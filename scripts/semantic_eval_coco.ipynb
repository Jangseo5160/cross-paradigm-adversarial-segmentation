{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd215359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deeplabv3_eval_multi_dirs.py\n",
    "import os, glob, cv2, numpy as np, json\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from PIL import Image\n",
    "from mmseg.apis import init_model, inference_model\n",
    "from mmseg.utils import register_all_modules\n",
    "\n",
    "# ===================== User settings =====================\n",
    "CONFIG_FILE = r'C:/Users/heheh/mmsegmentation/configs/deeplabv3/deeplabv3_r50-d8_4xb4-80k_coco-stuff164k-512x512.py'\n",
    "CHECKPOINT  = r'C:/Users/heheh/mmsegmentation/checkpoints/deeplabv3_r50-d8_512x512_4x4_80k_coco-stuff164k_20210709_163016-88675c24.pth'\n",
    "\n",
    "# Name -> image folder (jpg). Use matching COCO val2017 basenames.\n",
    "IMAGE_DIRS = {\n",
    "    'Clean'       : r'C:/Users/heheh/val2017/val2017',\n",
    "    'Semantic_Adv': r'C:/Users/heheh/mmsegmentation/data/semantic_adv_deeplabv3', \n",
    "    'instance_pgd': r'C:/Users/heheh/mmdetection/data/coco/instance_maskrcnn_adv',\n",
    "    'Panoptic_Adv': r'C:/Users/heheh/mmdetection/data/coco/panoptic_fpn_adv',\n",
    "}\n",
    "# Ground-truth PNG label maps (COCO-Stuff 164k)\n",
    "GT_DIR = r'C:/Users/heheh/mmsegmentation/data/coco_stuff164k/annotations/val2017'\n",
    "\n",
    "# Evaluate only a subset for speed (None = all in the intersection)\n",
    "MAX_SAMPLES = 5000\n",
    "\n",
    "COCO_STUFF_LABEL_MAP = {\n",
    "    0:0, 1:1, 2:2, 3:3, 4:4, 5:5, 6:6, 7:7, 8:8, 9:9, 10:10,\n",
    "    11:11, 13:12, 14:13, 15:14, 16:15, 17:16, 18:17, 19:18, 20:19, 21:20,\n",
    "    22:21, 23:22, 24:23, 25:24, 27:25, 28:26, 31:27, 32:28, 33:29, 34:30,\n",
    "    35:31, 36:32, 37:33, 38:34, 39:35, 40:36, 41:37, 42:38, 43:39, 44:40,\n",
    "    46:41, 47:42, 48:43, 49:44, 50:45, 51:46, 52:47, 53:48, 54:49, 55:50,\n",
    "    56:51, 57:52, 58:53, 59:54, 60:55, 61:56, 62:57, 63:58, 64:59, 65:60,\n",
    "    67:61, 70:62, 72:63, 73:64, 74:65, 75:66, 76:67, 77:68, 78:69, 79:70,\n",
    "    80:71, 81:72, 82:73, 84:74, 85:75, 86:76, 87:77, 88:78, 89:79, 90:80,\n",
    "    92:81, 93:82, 94:83, 95:84, 96:85, 97:86, 98:87, 99:88, 100:89, 101:90,\n",
    "    102:91, 103:92, 104:93, 105:94, 106:95, 107:96, 108:97, 109:98, 110:99, 111:100,\n",
    "    112:101, 113:102, 114:103, 115:104, 116:105, 117:106, 118:107, 119:108, 120:109, 121:110,\n",
    "    122:111, 123:112, 124:113, 125:114, 126:115, 127:116, 128:117, 129:118, 130:119, 131:120,\n",
    "    132:121, 133:122, 134:123, 135:124, 136:125, 137:126, 138:127, 139:128, 140:129, 141:130,\n",
    "    142:131, 143:132, 144:133, 145:134, 146:135, 147:136, 148:137, 149:138, 150:139, 151:140,\n",
    "    152:141, 153:142, 154:143, 155:144, 156:145, 157:146, 158:147, 159:148, 160:149, 161:150,\n",
    "    162:151, 163:152, 164:153, 165:154, 166:155, 167:156, 168:157, 169:158, 170:159, 171:160,\n",
    "    172:161, 173:162, 174:163, 175:164, 176:165, 177:166, 178:167, 179:168, 180:169, 181:170,\n",
    "    182:171, 255:255\n",
    "}\n",
    "\n",
    "# Save CSVs\n",
    "SAVE_DIR = r'C:/Users/heheh/mmsegmentation/data/eval_out'\n",
    "SAVE_SUMMARY_CSV = True\n",
    "SAVE_PER_CLASS_IOU_CSV = True\n",
    "\n",
    "IGNORE_INDEX = 255\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# =========================================================\n",
    "def build_label_lut(mapping: dict, ignore_index=255):\n",
    "    size = max(max(mapping.keys()), ignore_index) + 1   # 256 works, but compute robustly\n",
    "    lut = np.full(size, ignore_index, dtype=np.int64)\n",
    "    for k, v in mapping.items():\n",
    "        lut[k] = v\n",
    "    return lut\n",
    "\n",
    "# replace your OpenCV-based GT loader with this\n",
    "def load_gt_png(path, remap_lut=None, num_classes=None, ignore_index=255):\n",
    "    with Image.open(path) as img:\n",
    "        # preserve palette indices; don't convert to RGB\n",
    "        if img.mode in ('P', 'L', 'I'):\n",
    "            gt = np.array(img)\n",
    "        else:\n",
    "            gt = np.array(img.convert('P'))\n",
    "    if remap_lut is not None:\n",
    "        # apply LUT safely\n",
    "        max_idx = remap_lut.shape[0] - 1\n",
    "        gt = remap_lut[np.clip(gt, 0, max_idx)]\n",
    "    # clamp any stray ids to ignore\n",
    "    if num_classes is not None:\n",
    "        bad = (gt != ignore_index) & ((gt < 0) | (gt >= num_classes))\n",
    "        if bad.any():\n",
    "            gt = np.where(bad, ignore_index, gt)\n",
    "    return gt.astype(np.int64)\n",
    "\n",
    "def basenames_in(dir_path, ext):\n",
    "    paths = glob.glob(os.path.join(dir_path, f'*.{ext}'))\n",
    "    return set(os.path.splitext(os.path.basename(p))[0] for p in paths)\n",
    "\n",
    "def fast_confusion_update(conf_mat, pred, gt, num_classes, ignore_index=255):\n",
    "    mask = gt != ignore_index\n",
    "    if not np.any(mask):\n",
    "        return\n",
    "    gt_v = gt[mask]\n",
    "    pr_v = pred[mask]\n",
    "    valid = (gt_v >= 0) & (gt_v < num_classes) & (pr_v >= 0) & (pr_v < num_classes)\n",
    "    if not np.any(valid):\n",
    "        return\n",
    "    gt_v = gt_v[valid]\n",
    "    pr_v = pr_v[valid]\n",
    "    idx = gt_v * num_classes + pr_v\n",
    "    counts = np.bincount(idx, minlength=num_classes * num_classes)\n",
    "    conf_mat += counts.reshape(num_classes, num_classes)\n",
    "\n",
    "def metrics_from_confusion(conf_mat):\n",
    "    inter = np.diag(conf_mat)\n",
    "    area_gt = conf_mat.sum(1)\n",
    "    area_pr = conf_mat.sum(0)\n",
    "    union = area_gt + area_pr - inter\n",
    "\n",
    "    iou = np.divide(inter, union, out=np.zeros_like(inter, dtype=float), where=union > 0)\n",
    "    acc = np.divide(inter, area_gt, out=np.zeros_like(inter, dtype=float), where=area_gt > 0)\n",
    "\n",
    "    valid = area_gt > 0\n",
    "    mIoU = float(iou[valid].mean()) if np.any(valid) else 0.0\n",
    "    mAcc = float(acc[valid].mean()) if np.any(valid) else 0.0\n",
    "    aAcc = float(inter.sum() / max(area_gt.sum(), 1))\n",
    "    freq = area_gt / max(area_gt.sum(), 1)\n",
    "    fwIoU = float((freq * iou).sum())\n",
    "\n",
    "    return dict(mIoU=mIoU, mAcc=mAcc, aAcc=aAcc, fwIoU=fwIoU,\n",
    "                iou=iou, acc=acc, area_gt=area_gt, area_pred=area_pr, area_inter=inter)\n",
    "\n",
    "def evaluate_dir(model, img_dir, gt_dir, basenames, num_classes, remap_lut=None):\n",
    "    conf = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
    "    missing = 0\n",
    "    for base in tqdm(basenames, ncols=100, desc=os.path.basename(img_dir) or img_dir):\n",
    "        img_path = os.path.join(img_dir, base + '.jpg')\n",
    "        gt_path  = os.path.join(gt_dir,  base + '.png')\n",
    "        if not (os.path.isfile(img_path) and os.path.isfile(gt_path)):\n",
    "            missing += 1\n",
    "            continue\n",
    "\n",
    "        res = inference_model(model, img_path)\n",
    "        if hasattr(res, 'pred_sem_seg'):\n",
    "            pred = res.pred_sem_seg.data.squeeze(0).to('cpu').numpy().astype(np.int64)\n",
    "        elif hasattr(res, 'seg_logits'):\n",
    "            pred = torch.argmax(res.seg_logits.data, dim=1).squeeze(0).to('cpu').numpy().astype(np.int64)\n",
    "        else:\n",
    "            raise AttributeError('No pred_sem_seg or seg_logits in result.')\n",
    "\n",
    "        gt = load_gt_png(gt_path, remap_lut=remap_lut, num_classes=num_classes, ignore_index=IGNORE_INDEX)\n",
    "        if pred.shape != gt.shape:\n",
    "            pred = cv2.resize(pred, (gt.shape[1], gt.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        fast_confusion_update(conf, pred, gt, num_classes, ignore_index=IGNORE_INDEX)\n",
    "\n",
    "    return metrics_from_confusion(conf), missing\n",
    "\n",
    "def main():\n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "    register_all_modules()\n",
    "    model = init_model(CONFIG_FILE, CHECKPOINT, device=DEVICE)\n",
    "\n",
    "    classes = model.dataset_meta.get('classes', None)\n",
    "    num_classes = len(classes) if classes is not None else model.decode_head.num_classes\n",
    "    print(f'[INFO] Device: {DEVICE} | num_classes={num_classes}')\n",
    "    print(f'[INFO] GT dir: {GT_DIR}')\n",
    "    for k, v in IMAGE_DIRS.items():\n",
    "        print(f'[INFO] \"{k}\" -> {v}')\n",
    "        \n",
    "    probe_paths = glob.glob(os.path.join(GT_DIR, '*.png'))[:10]\n",
    "    needs_remap = False\n",
    "    for p in probe_paths:\n",
    "        g = load_gt_png(p, remap_lut=None, num_classes=None, ignore_index=IGNORE_INDEX)\n",
    "        if np.any((g != IGNORE_INDEX) & ((g < 0) | (g >= num_classes))):\n",
    "            needs_remap = True\n",
    "            break\n",
    "        \n",
    "    remap_lut = None\n",
    "    if needs_remap:\n",
    "        remap_lut = build_label_lut(COCO_STUFF_LABEL_MAP, ignore_index=IGNORE_INDEX)\n",
    "        # sanity: the remapped range should match model classes\n",
    "        max_after = remap_lut.max()\n",
    "        if max_after != num_classes - 1:\n",
    "            print(f'[WARN] Remap LUT max={max_after}, but num_classes-1={num_classes-1}. '\n",
    "                'Verify your mapping matches the model labels.')\n",
    "        print('[INFO] Applying COCO_STUFF_LABEL_MAP to GT.')\n",
    "    else:\n",
    "        print('[INFO] GT appears already remapped; no label map applied.') \n",
    "               \n",
    "    # -------- Build a common intersection of basenames --------\n",
    "    gt_bases   = basenames_in(GT_DIR, 'png')\n",
    "    img_bag = [basenames_in(p, 'jpg') for p in IMAGE_DIRS.values()]\n",
    "    common = gt_bases.copy()\n",
    "    for s in img_bag:\n",
    "        common &= s\n",
    "\n",
    "    if not common:\n",
    "        raise RuntimeError('No common basenames across GT and all IMAGE_DIRS. Check folders.')\n",
    "\n",
    "    common = sorted(common)\n",
    "    if MAX_SAMPLES is not None:\n",
    "        common = common[:MAX_SAMPLES]\n",
    "\n",
    "    print(f'[INFO] Using {len(common)} common images for all dirs (fair comparison).')\n",
    "\n",
    "    # -------- Evaluate each directory --------\n",
    "    results = {}\n",
    "    for name, img_dir in IMAGE_DIRS.items():\n",
    "        print(f'\\n=== Evaluating: {name} ===')\n",
    "        out, missing = evaluate_dir(model, img_dir, GT_DIR, common, num_classes, remap_lut=remap_lut)\n",
    "        results[name] = out\n",
    "        print(f'[{name}] mIoU={out[\"mIoU\"]:.4f}  mAcc={out[\"mAcc\"]:.4f}  aAcc={out[\"aAcc\"]:.4f}  fwIoU={out[\"fwIoU\"]:.4f}')\n",
    "        if missing > 0:\n",
    "            print(f'[{name}] WARNING: {missing} missing pairs (should be 0 because of intersection).')\n",
    "\n",
    "    # -------- Optional: deltas vs \"Clean\" --------\n",
    "    if 'Clean' in results:\n",
    "        base = results['Clean']\n",
    "        print('\\n--- Drops vs Clean (absolute) ---')\n",
    "        for name, out in results.items():\n",
    "            diou = out['mIoU'] - base['mIoU']\n",
    "            dacc = out['aAcc'] - base['aAcc']\n",
    "            print(f'{name:<14s} ΔmIoU={diou:+.4f}  ΔaAcc={dacc:+.4f}')\n",
    "\n",
    "    # -------- Save CSVs --------\n",
    "    if SAVE_SUMMARY_CSV:\n",
    "        import csv\n",
    "        sum_path = os.path.join(SAVE_DIR, 'summary.csv')\n",
    "        base_miou = results.get('Clean', {}).get('mIoU', None)\n",
    "        base_aacc = results.get('Clean', {}).get('aAcc', None)\n",
    "        \n",
    "        with open(sum_path, 'w', newline='') as f:\n",
    "            w = csv.writer(f)\n",
    "            w.writerow(['name', 'mIoU', 'mAcc', 'aAcc', 'fwIoU', 'ΔmIoU_vs_Clean', 'ΔaAcc_vs_Clean'])\n",
    "            for name, out in results.items():\n",
    "                d_miou = '' if base_miou is None else f'{(out[\"mIoU\"] - base_miou):.6f}'\n",
    "                d_aacc = '' if base_aacc is None else f'{(out[\"aAcc\"] - base_aacc):.6f}'\n",
    "\n",
    "                w.writerow([name, f'{out[\"mIoU\"]:.6f}', f'{out[\"mAcc\"]:.6f}', f'{out[\"aAcc\"]:.6f}', f'{out[\"fwIoU\"]:.6f}', d_miou, d_aacc])\n",
    "        print(f'[INFO] Wrote {sum_path}')\n",
    "\n",
    "    if SAVE_PER_CLASS_IOU_CSV:\n",
    "        import csv\n",
    "        pci_path = os.path.join(SAVE_DIR, 'per_class_iou.csv')\n",
    "        names = list(results.keys())\n",
    "        with open(pci_path, 'w', newline='') as f:\n",
    "            w = csv.writer(f)\n",
    "            header = ['class_id', 'class_name'] + [f'IoU_{n}' for n in names]\n",
    "            if 'Clean' in results:\n",
    "                header += [f'IoU_Delta_vs_Clean_{n}' for n in names if n != 'Clean']\n",
    "            w.writerow(header)\n",
    "\n",
    "            for cid in range(num_classes):\n",
    "                row = [cid, classes[cid] if classes else f'class_{cid}']\n",
    "                ious = [results[n]['iou'][cid] for n in names]\n",
    "                row += [f'{x:.6f}' for x in ious]\n",
    "                if 'Clean' in results:\n",
    "                    base = results['Clean']['iou'][cid]\n",
    "                    row += [f'{results[n][\"iou\"][cid]-base:.6f}' for n in names if n != 'Clean']\n",
    "                w.writerow(row)\n",
    "        print(f'[INFO] Wrote {pci_path}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
