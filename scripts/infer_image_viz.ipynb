{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9dbeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "v4: MMSeg direct inference (no pipeline / no PackSegInputs).\n",
    "    - Build MMSeg model from cfg/ckpt (init_model)\n",
    "    - Read image as numpy, build minimal SegDataSample meta\n",
    "    - Use model.data_preprocessor + model.predict\n",
    "    - Visualize via model.visualizer.add_datasample\n",
    "\n",
    "MMDet paths (Mask R-CNN, PanopticFPN) remain as in v2.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ======== USER CONFIG ========\n",
    "# DeeplabV3 (MMSeg, COCO-Stuff-164k)\n",
    "MMSEG_CFG  = r'C:/Users/heheh/mmsegmentation/configs/deeplabv3/deeplabv3_r50-d8_4xb4-80k_coco-stuff164k-512x512.py'   # EDIT\n",
    "MMSEG_CKPT = r'C:/Users/heheh/mmsegmentation/checkpoints/deeplabv3_r50-d8_512x512_4x4_80k_coco-stuff164k_20210709_163016-88675c24.pth'                 # EDIT\n",
    "\n",
    "# Mask R-CNN (MMDet)\n",
    "MMDET_MASKRCNN_CFG  = r'C:/Users/heheh/mmdetection/configs/mask_rcnn/mask-rcnn_r50_fpn_1x_coco.py'\n",
    "MMDET_MASKRCNN_CKPT = r'C:/Users/heheh/mmdetection/checkpoints/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth'\n",
    "\n",
    "# Panoptic FPN (MMDet)\n",
    "MMDET_PANO_CFG  = r'C:/Users/heheh/mmdetection/configs/panoptic_fpn/panoptic-fpn_r50_fpn_1x_coco.py'\n",
    "MMDET_PANO_CKPT = r'C:/Users/heheh/mmdetection/checkpoints/panoptic_fpn_r50_fpn_1x_coco_20210821_101153-9668fd13.pth'\n",
    "\n",
    "DEVICE = 'cuda'  # or 'cpu'\n",
    "\n",
    "# --- Datasets (directories) ---\n",
    "# Each directory must contain image files named identically across variants (e.g., \"000000123456.jpg\").\n",
    "CLEAN_DIR     = r'C:/Users/heheh/mmdetection/data/coco/val2017'                 # originals\n",
    "SEM_ADV_DIR   = r'C:/Users/heheh/mmsegmentation/data/semantic_adv_deeplabv3'          # semantic adversarial\n",
    "INST_ADV_DIR  = r'C:/Users/heheh/mmdetection/data/coco/instance_maskrcnn_adv'           # instance adversarial\n",
    "PANO_ADV_DIR  = r'C:/Users/heheh/mmdetection/data/coco/panoptic_fpn_adv'       # panoptic adversarial\n",
    "\n",
    "NUM_IMAGES = 5\n",
    "RANDOM_SEED = 123\n",
    "\n",
    "# Output directory\n",
    "OUT_DIR = r'C:/Users/heheh/cross_paradigm_vis'\n",
    "\n",
    "# Optional uniform resize before inference for nicer grids (None to disable)\n",
    "RESIZE_TO = None  # e.g., (512, 512)\n",
    "\n",
    "# Opacity for MMSeg overlay\n",
    "OPACITY = 1.0\n",
    "\n",
    "# =============================\n",
    "\n",
    "def _init_mmseg_model(cfg, ckpt, device='cuda'):\n",
    "    from mmseg.apis import init_model as init_segmentor\n",
    "    model = init_segmentor(cfg, ckpt, device=device)\n",
    "    model.eval()\n",
    "    # Give the visualizer a save dir\n",
    "    if getattr(model, 'visualizer', None) is not None:\n",
    "        try:\n",
    "            model.visualizer.set_save_dir(OUT_DIR)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return model\n",
    "\n",
    "def _mmseg_predict_direct_and_vis(model, img_path, out_file, opacity=0.75):\n",
    "    \"\"\"Direct MMSeg inference without pipeline. No PackSegInputs needed.\"\"\"\n",
    "    import torch\n",
    "    from mmseg.structures import SegDataSample\n",
    "\n",
    "    # Read image\n",
    "    img = np.array(Image.open(img_path).convert('RGB'))\n",
    "    H, W = img.shape[:2]\n",
    "\n",
    "    # Build minimal data_sample with metainfo\n",
    "    data_sample = SegDataSample()\n",
    "    data_sample.set_metainfo(dict(\n",
    "        ori_shape=(H, W),\n",
    "        img_shape=(H, W),\n",
    "        pad_shape=(H, W),\n",
    "        scale_factor=1.0,\n",
    "        img_path=img_path\n",
    "    ))\n",
    "\n",
    "    # Preprocess (handles normalization, channel conversion, stacking)\n",
    "    batch = model.data_preprocessor(\n",
    "    data=dict(inputs=[img], data_samples=[data_sample]),\n",
    "    training=False\n",
    "    )  \n",
    "    inputs = batch['inputs']          # Tensor (N,C,H,W)\n",
    "    samples = batch['data_samples']   # List[SegDataSample]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model.predict(inputs, samples)  # List[SegDataSample]\n",
    "\n",
    "    # Visualize\n",
    "    vis = getattr(model, 'visualizer', None)\n",
    "    if vis is None:\n",
    "        from mmseg.visualization import SegLocalVisualizer\n",
    "        vis = SegLocalVisualizer()\n",
    "        vis.dataset_meta = getattr(model, 'dataset_meta', None)\n",
    "    else:\n",
    "        if getattr(vis, 'dataset_meta', None) is None:\n",
    "            vis.dataset_meta = getattr(model, 'dataset_meta', None)\n",
    "\n",
    "    vis.add_datasample(\n",
    "        name='pred',\n",
    "        image=img,\n",
    "        data_sample=preds[0],\n",
    "        draw_gt=False,\n",
    "        out_file=out_file,\n",
    "        wait_time=0,\n",
    "        opacity=opacity\n",
    "    )\n",
    "\n",
    "def _init_mmdet_model(cfg, ckpt, device='cuda'):\n",
    "    from mmdet.apis import init_detector\n",
    "    model = init_detector(cfg, ckpt, device=device)\n",
    "    if getattr(model, 'visualizer', None) is not None:\n",
    "        try:\n",
    "            model.visualizer.set_save_dir(OUT_DIR)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return model\n",
    "\n",
    "def _mmdet_infer_and_vis(model, img_path, out_file):\n",
    "    from mmdet.apis import inference_detector\n",
    "    result = inference_detector(model, img_path)\n",
    "\n",
    "    img = np.array(Image.open(img_path).convert('RGB'))\n",
    "    vis = getattr(model, 'visualizer', None)\n",
    "    if vis is None:\n",
    "        from mmdet.visualization import DetLocalVisualizer\n",
    "        vis = DetLocalVisualizer()\n",
    "        meta = getattr(model, 'dataset_meta', None) or getattr(model, 'metainfo', None)\n",
    "        vis.dataset_meta = meta\n",
    "    else:\n",
    "        if getattr(vis, 'dataset_meta', None) is None:\n",
    "            meta = getattr(model, 'dataset_meta', None) or getattr(model, 'metainfo', None)\n",
    "            vis.dataset_meta = meta\n",
    "\n",
    "    vis.add_datasample(\n",
    "        name='pred',\n",
    "        image=img,\n",
    "        data_sample=result,\n",
    "        draw_gt=False,\n",
    "        out_file=out_file,\n",
    "        wait_time=0\n",
    "    )\n",
    "\n",
    "def _maybe_resize(src_path, dst_path, size_wh=None):\n",
    "    if size_wh is None:\n",
    "        return src_path\n",
    "    W, H = size_wh\n",
    "    img = Image.open(src_path).convert('RGB').resize((W, H), Image.BILINEAR)\n",
    "    os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "    img.save(dst_path, quality=95)\n",
    "    return dst_path\n",
    "\n",
    "def _collect_basenames(img_dir: str) -> List[str]:\n",
    "    exts = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff', '.webp')\n",
    "    names = [f for f in os.listdir(img_dir) if f.lower().endswith(exts)]\n",
    "    names.sort()\n",
    "    return names\n",
    "\n",
    "def _compose_grid(cells: Dict[Tuple[int,int], str],\n",
    "                  n_rows: int, n_cols: int,\n",
    "                  titles_row: List[str], titles_col: List[str],\n",
    "                  out_file: str):\n",
    "    tile_w, tile_h = 0, 0\n",
    "    pil_tiles = {}\n",
    "    for r in range(n_rows):\n",
    "        for c in range(n_cols):\n",
    "            p = cells.get((r, c))\n",
    "            if p and os.path.isfile(p):\n",
    "                im = Image.open(p).convert('RGB')\n",
    "            else:\n",
    "                im = Image.new('RGB', (640, 480), color=(230,230,230))\n",
    "                ImageDraw.Draw(im).text((10, 10), \"MISSING\", fill=(0,0,0))\n",
    "            pil_tiles[(r,c)] = im\n",
    "            tile_w = max(tile_w, im.width)\n",
    "            tile_h = max(tile_h, im.height)\n",
    "\n",
    "    header_h = 40\n",
    "    left_w   = 160\n",
    "    gap = 6\n",
    "    total_w = left_w + n_cols*tile_w + (n_cols+1)*gap\n",
    "    total_h = header_h + n_rows*tile_h + (n_rows+1)*gap\n",
    "\n",
    "    canvas = Image.new('RGB', (total_w, total_h), color=(255,255,255))\n",
    "    draw = ImageDraw.Draw(canvas)\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 20)\n",
    "    except Exception:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    for c in range(n_cols):\n",
    "        x = left_w + gap + c*(tile_w + gap)\n",
    "        y = gap\n",
    "        draw.text((x, y), titles_col[c], fill=(0,0,0), font=font)\n",
    "\n",
    "    for r in range(n_rows):\n",
    "        ry = header_h + gap + r*(tile_h + gap)\n",
    "        draw.text((10, ry + 10), titles_row[r], fill=(0,0,0), font=font)\n",
    "        for c in range(n_cols):\n",
    "            x = left_w + gap + c*(tile_w + gap)\n",
    "            y = header_h + gap + r*(tile_h + gap)\n",
    "            im = pil_tiles[(r,c)]\n",
    "            canvas.paste(im, (x, y))\n",
    "\n",
    "    os.makedirs(os.path.dirname(out_file), exist_ok=True)\n",
    "    canvas.save(out_file, quality=95)\n",
    "\n",
    "def main():\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "\n",
    "    for label, d in [('Clean', CLEAN_DIR), ('Semantic-Adv', SEM_ADV_DIR),\n",
    "                     ('Instance-Adv', INST_ADV_DIR), ('Panoptic-Adv', PANO_ADV_DIR)]:\n",
    "        if not os.path.isdir(d):\n",
    "            print(f\"[WARN] Directory does not exist: {d} ({label})\")\n",
    "\n",
    "    basenames = _collect_basenames(CLEAN_DIR)\n",
    "    if NUM_IMAGES is not None and len(basenames) > NUM_IMAGES:\n",
    "        basenames = random.sample(basenames, NUM_IMAGES)\n",
    "    print(f\"[INFO] Will visualize {len(basenames)} images.\")\n",
    "\n",
    "    vis_dir = os.path.join(OUT_DIR, 'cells')\n",
    "    grid_dir = os.path.join(OUT_DIR, 'grids')\n",
    "    os.makedirs(vis_dir, exist_ok=True)\n",
    "    os.makedirs(grid_dir, exist_ok=True)\n",
    "\n",
    "    print(\"[INFO] Loading models...\")\n",
    "    seg_model  = _init_mmseg_model(MMSEG_CFG, MMSEG_CKPT, device=DEVICE)\n",
    "    mask_model = _init_mmdet_model(MMDET_MASKRCNN_CFG, MMDET_MASKRCNN_CKPT, device=DEVICE)\n",
    "    pano_model = _init_mmdet_model(MMDET_PANO_CFG, MMDET_PANO_CKPT, device=DEVICE)\n",
    "\n",
    "    dataset_rows = OrderedDict([\n",
    "        ('Clean',        CLEAN_DIR),\n",
    "        ('Semantic-Adv', SEM_ADV_DIR),\n",
    "        ('Instance-Adv', INST_ADV_DIR),\n",
    "        ('Panoptic-Adv', PANO_ADV_DIR),\n",
    "    ])\n",
    "    model_cols = OrderedDict([\n",
    "        ('DeeplabV3',  ('mmseg', seg_model)),\n",
    "        ('Mask R-CNN', ('mmdet', mask_model)),\n",
    "        ('PanopticFPN',('mmdet', pano_model)),\n",
    "    ])\n",
    "\n",
    "    tmp_resize_root = os.path.join(OUT_DIR, '_tmp_resized') if RESIZE_TO is not None else None\n",
    "    if tmp_resize_root:\n",
    "        os.makedirs(tmp_resize_root, exist_ok=True)\n",
    "\n",
    "    for i, base in enumerate(basenames):\n",
    "        print(f\"[{i+1}/{len(basenames)}] {base}\")\n",
    "        cell_paths: Dict[Tuple[int,int], str] = {}\n",
    "\n",
    "        for r, (row_name, row_dir) in enumerate(dataset_rows.items()):\n",
    "            src_img = os.path.join(row_dir, base)\n",
    "            if not os.path.isfile(src_img):\n",
    "                print(f\"  [WARN] Missing image for row {row_name}: {src_img}\")\n",
    "                resized_path = None\n",
    "            else:\n",
    "                if tmp_resize_root:\n",
    "                    resized_path = _maybe_resize(\n",
    "                        src_img,\n",
    "                        os.path.join(tmp_resize_root, row_name, base),\n",
    "                        RESIZE_TO\n",
    "                    )\n",
    "                else:\n",
    "                    resized_path = src_img\n",
    "\n",
    "            for c, (col_name, (family, model)) in enumerate(model_cols.items()):\n",
    "                out_cell = os.path.join(vis_dir, f\"{os.path.splitext(base)[0]}__{row_name.replace(' ','_')}__{col_name.replace(' ','_')}.jpg\")\n",
    "                if resized_path is None:\n",
    "                    cell_paths[(r, c)] = None\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    if family == 'mmseg':\n",
    "                        _mmseg_predict_direct_and_vis(model, resized_path, out_cell, opacity=OPACITY)\n",
    "                    else:\n",
    "                        _mmdet_infer_and_vis(model, resized_path, out_cell)\n",
    "                    cell_paths[(r, c)] = out_cell\n",
    "                except Exception as e:\n",
    "                    print(f\"  [ERR] {col_name} failed on {row_name}/{base}: {e}\")\n",
    "                    cell_paths[(r, c)] = None\n",
    "\n",
    "        grid_path = os.path.join(grid_dir, f\"{os.path.splitext(base)[0]}__grid.jpg\")\n",
    "        _compose_grid(\n",
    "            cells=cell_paths,\n",
    "            n_rows=len(dataset_rows),\n",
    "            n_cols=len(model_cols),\n",
    "            titles_row=list(dataset_rows.keys()),\n",
    "            titles_col=list(model_cols.keys()),\n",
    "            out_file=grid_path\n",
    "        )\n",
    "\n",
    "    print(f\"[DONE] Grids saved to: {grid_dir}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
