{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c3e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "from mmengine.config import Config\n",
    "from mmengine.runner import Runner\n",
    "from mmdet.registry import DATASETS\n",
    "from mmengine.registry import DefaultScope\n",
    "\n",
    "# ========= User paths =========\n",
    "CONFIG ='C:/Users/heheh/mmdetection/configs/mask_rcnn/mask-rcnn_r50_fpn_1x_coco.py'\n",
    "CHECKPOINT = 'C:/Users/heheh/mmdetection/checkpoints/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth'\n",
    "DATA_ROOT = 'C:/Users/heheh/mmdetection/data/coco'\n",
    "ANN_FILE  = os.path.join(DATA_ROOT, 'annotations', 'instances_val2017.json')\n",
    "CLEAN_IMG_DIR = os.path.join(DATA_ROOT, 'val2017')\n",
    "\n",
    "# Add any number of adversarial dirs here (only those that exist will be used)\n",
    "ADV_DIRS = {\n",
    "    'deeplabv3_pgd': r'C:/Users/heheh/mmsegmentation/data/semantic_adv_deeplabv3',\n",
    "    'maskrcnn_pgd':  r'C:/Users/heheh/mmdetection/data/coco/instance_maskrcnn_adv',\n",
    "    'panoptic_pgd':  r'C:/Users/heheh/mmdetection/data/coco/panoptic_fpn_adv',\n",
    "}\n",
    "\n",
    "OUT_DIR = './work_dirs/eval_multi'\n",
    "CSV_PATH = os.path.join(OUT_DIR, 'maskrcnn_clean_vs_adversarials.csv')\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ========= Helpers =========\n",
    "def ensure_mmdet_scope():\n",
    "    # Set/override the default registry scope so TRANSFORMS resolve to mmdet.*\n",
    "    try:\n",
    "        # If a scope is already active\n",
    "        DefaultScope.get_current_instance().set_scope('mmdet')\n",
    "    except Exception:\n",
    "        # If no scope yet, create one\n",
    "        try:\n",
    "            DefaultScope.get_instance('eval-scope', scope_name='mmdet')\n",
    "        except Exception:\n",
    "            pass\n",
    "def make_cfg(img_prefix, indices, work_dir):\n",
    "    cfg = Config.fromfile(CONFIG)\n",
    "    cfg.default_scope = 'mmdet'\n",
    "    cfg.load_from = CHECKPOINT\n",
    "    cfg.work_dir = work_dir\n",
    "    if hasattr(cfg, 'visualizer'):\n",
    "        cfg.visualizer.vis_backends = None\n",
    "    # dataloader\n",
    "    cfg.test_dataloader.batch_size = 2\n",
    "    cfg.test_dataloader.num_workers = 2\n",
    "    ds = cfg.test_dataloader.dataset\n",
    "    ds.type = 'CocoDataset'\n",
    "    ds.data_root = DATA_ROOT\n",
    "    ds.ann_file = ANN_FILE\n",
    "    ds.data_prefix = dict(img=img_prefix)\n",
    "    ds.test_mode = True\n",
    "    ds.indices = indices\n",
    "    # evaluator\n",
    "    cfg.test_evaluator = dict(\n",
    "        type='CocoMetric',\n",
    "        ann_file=ANN_FILE,\n",
    "        metric=['bbox', 'segm'],\n",
    "        format_only=False\n",
    "    )\n",
    "    return cfg\n",
    "\n",
    "def build_dataset_for_mapping(img_dir):\n",
    "    \"\"\"Build a CocoDataset once to map dataset index -> real img path.\"\"\"\n",
    "    tmp_cfg = make_cfg(img_dir, indices=None, work_dir=os.path.join(OUT_DIR, 'tmp'))\n",
    "    ensure_mmdet_scope() \n",
    "    return DATASETS.build(tmp_cfg.test_dataloader.dataset)\n",
    "\n",
    "def basenames_in_dir(d):\n",
    "    if not os.path.isdir(d):\n",
    "        return set()\n",
    "    exts = ('.jpg','.jpeg','.png')\n",
    "    return {os.path.splitext(os.path.basename(p))[0]\n",
    "            for p in glob.glob(os.path.join(d, '*'))\n",
    "            if p.lower().endswith(exts)}\n",
    "\n",
    "def compute_intersection_indices(clean_ds, dir_list):\n",
    "    \"\"\"\n",
    "    Build subset indices using the intersection of basenames that exist\n",
    "    in *all* provided directories and in the clean dataset.\n",
    "    \"\"\"\n",
    "    # map clean dataset base -> dataset index\n",
    "    base_to_idx = {}\n",
    "    for i in range(len(clean_ds)):\n",
    "        info = clean_ds.get_data_info(i)\n",
    "        base = os.path.splitext(os.path.basename(info['img_path']))[0]\n",
    "        base_to_idx[base] = i\n",
    "\n",
    "    # intersection of basenames across all dirs\n",
    "    sets = []\n",
    "    for d in dir_list:\n",
    "        s = basenames_in_dir(d)\n",
    "        if not s:\n",
    "            print(f'[WARN] Empty or missing dir skipped in intersection: {d}')\n",
    "        sets.append(s)\n",
    "    # Always include clean basenames (so indices are valid)\n",
    "    sets.append(set(base_to_idx.keys()))\n",
    "\n",
    "    common = set.intersection(*sets) if sets else set()\n",
    "    indices = sorted([base_to_idx[b] for b in common if b in base_to_idx])\n",
    "    return indices, common\n",
    "\n",
    "def eval_one(label, img_dir, indices):\n",
    "    cfg = make_cfg(img_dir, indices, work_dir=os.path.join(OUT_DIR, f'eval_{label}'))\n",
    "    runner = Runner.from_cfg(cfg)\n",
    "    metrics = runner.test()  # dict\n",
    "    # Flatten to simple dict with label\n",
    "    row = {'set': label, 'count': len(indices)}\n",
    "    for k, v in metrics.items():\n",
    "        row[k] = v\n",
    "    return row\n",
    "\n",
    "def add_drop_columns(df, clean_row_name='clean'):\n",
    "    \"\"\"Add drop (adv - clean) and drop% columns vs clean for key metrics.\"\"\"\n",
    "    # pivot: set rows indexed by 'set'\n",
    "    df = df.set_index('set')\n",
    "    if clean_row_name not in df.index:\n",
    "        raise RuntimeError('Clean results missing; cannot compute drops.')\n",
    "    clean = df.loc[clean_row_name]\n",
    "\n",
    "    keys = [\n",
    "        'coco/bbox_mAP','coco/bbox_mAP_50','coco/bbox_mAP_75',\n",
    "        'coco/segm_mAP','coco/segm_mAP_50','coco/segm_mAP_75'\n",
    "    ]\n",
    "    for k in keys:\n",
    "        col_drop = f'{k}_drop'\n",
    "        col_drop_pct = f'{k}_drop_pct'\n",
    "        df[col_drop] = df[k] - float(clean[k])\n",
    "        # relative drop % (negative means a drop)\n",
    "        df[col_drop_pct] = 100.0 * (df[k] - float(clean[k])) / max(1e-8, float(clean[k]))\n",
    "\n",
    "    # \"Success rate\" = relative drop at AP50 (bounded to [0,1])\n",
    "    for k, name in [('coco/bbox_mAP_50','success_rate_bbox'),\n",
    "                    ('coco/segm_mAP_50','success_rate_segm')]:\n",
    "        sr = 1.0 - (df[k] / max(1e-8, float(clean[k])))\n",
    "        df[name] = sr.clip(lower=0.0, upper=1.0)\n",
    "\n",
    "    # move clean to top again and reset index for CSV\n",
    "    return df.reset_index()\n",
    "\n",
    "# ========= Run =========\n",
    "# Build clean dataset mapping\n",
    "clean_ds = build_dataset_for_mapping(CLEAN_IMG_DIR)\n",
    "\n",
    "# Keep only adversarial dirs that actually exist\n",
    "adv_dirs_exist = {k:v for k,v in ADV_DIRS.items() if os.path.isdir(v)}\n",
    "if not adv_dirs_exist:\n",
    "    raise RuntimeError('No adversarial directories found. Check ADV_DIRS paths.')\n",
    "\n",
    "# Build a *common* subset across all adv dirs (and clean)\n",
    "indices, common_bases = compute_intersection_indices(clean_ds, list(adv_dirs_exist.values()))\n",
    "print(f'[INFO] Common subset size (intersection across adv dirs): {len(indices)}')\n",
    "# --- Limit to 10 images ---\n",
    "N = 5000                    # how many images to test\n",
    "SAMPLE_MODE = 'first'      # 'first' or 'random'\n",
    "RANDOM_SEED = 123\n",
    "\n",
    "if len(indices) > N:\n",
    "    if SAMPLE_MODE == 'random':\n",
    "        import random\n",
    "        random.seed(RANDOM_SEED)\n",
    "        indices = sorted(random.sample(indices, N))\n",
    "    else:\n",
    "        indices = indices[:N]\n",
    "\n",
    "print(f'[INFO] Using {len(indices)} images for evaluation (mode={SAMPLE_MODE}).')\n",
    "\n",
    "# Evaluate clean on that subset\n",
    "rows = []\n",
    "rows.append(eval_one('clean', CLEAN_IMG_DIR, indices))\n",
    "\n",
    "# Evaluate each adv dir on the same subset\n",
    "for label, img_dir in adv_dirs_exist.items():\n",
    "    print(f'[INFO] Evaluating {label} on {len(indices)} images …')\n",
    "    rows.append(eval_one(label, img_dir, indices))\n",
    "\n",
    "# Build table, add drops/success-rate, save CSV\n",
    "df = pd.DataFrame(rows)\n",
    "df = add_drop_columns(df, clean_row_name='clean')\n",
    "print('\\n===== Summary (clean vs adversarials) =====')\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "df.to_csv(CSV_PATH, index=False)\n",
    "print(f'\\n[OK] Saved CSV → {CSV_PATH}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
