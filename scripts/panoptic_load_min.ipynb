{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef69dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate PanopticFPN on COCO panoptic val2017 (MMDetection 3.x)\n",
    "import os\n",
    "from mmengine.config import Config\n",
    "from mmengine.runner import Runner\n",
    "\n",
    "# ---- 1) Paths ----\n",
    "CONFIG = r'C:/Users/heheh/mmdetection/configs/panoptic_fpn/panoptic-fpn_r50_fpn_1x_coco.py'\n",
    "CHECKPOINT = r'C:/Users/heheh/mmdetection/checkpoints/panoptic_fpn_r50_fpn_1x_coco_20210821_101153-9668fd13.pth'\n",
    "DATA_ROOT = r'C:/Users/heheh/mmdetection/data/coco'\n",
    "PAN_JSON  = os.path.join(DATA_ROOT, 'annotations', 'panoptic_val2017.json')\n",
    "IMG_DIR   = os.path.join(DATA_ROOT, 'val2017')                   # same images as instance seg\n",
    "PAN_SEG   = os.path.join(DATA_ROOT, 'annotations', 'panoptic_val2017')  # PNG maps\n",
    "WORK_DIR  = './work_dirs/eval_panoptic_fpn'\n",
    "\n",
    "# ---- 2) Load cfg and override dataset/evaluator ----\n",
    "cfg = Config.fromfile(CONFIG)\n",
    "cfg.default_scope = 'mmdet'\n",
    "cfg.load_from = CHECKPOINT\n",
    "cfg.work_dir = WORK_DIR\n",
    "\n",
    "# dataloader settings (adjust if you like)\n",
    "cfg.test_dataloader.batch_size = 2\n",
    "cfg.test_dataloader.num_workers = 2\n",
    "\n",
    "# Point test dataset to COCO Panoptic format\n",
    "ds = cfg.test_dataloader.dataset\n",
    "ds.type = 'CocoPanopticDataset'              # <-- panoptic dataset type\n",
    "ds.data_root = DATA_ROOT\n",
    "ds.ann_file = PAN_JSON                       # <-- panoptic json\n",
    "ds.data_prefix = dict(img=IMG_DIR, seg=PAN_SEG)  # <-- img dir + seg png dir\n",
    "ds.test_mode = True\n",
    "\n",
    "# Evaluator: COCO panoptic metric (PQ/SQ/RQ)\n",
    "cfg.test_evaluator = dict(\n",
    "    type='CocoPanopticMetric',\n",
    "    ann_file=PAN_JSON, \n",
    "    seg_prefix=PAN_SEG,# GT panoptic json\n",
    "    format_only=False          # compute metrics instead of just dumping results\n",
    ")\n",
    "\n",
    "# If your config defines a visualizer, disable disk writing during test\n",
    "if hasattr(cfg, 'visualizer'):\n",
    "    cfg.visualizer.vis_backends = None\n",
    "\n",
    "# ---- 3) Run evaluation ----\n",
    "os.makedirs(cfg.work_dir, exist_ok=True)\n",
    "runner = Runner.from_cfg(cfg)\n",
    "metrics = runner.test()\n",
    "print(metrics)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
