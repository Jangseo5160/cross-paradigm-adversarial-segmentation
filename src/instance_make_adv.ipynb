{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e18bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PGD for MMDetection 3.x (Mask R-CNN, COCO)\n",
    "import os, torch\n",
    "from mmengine.config import Config\n",
    "from mmengine.runner import Runner\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# ========= User paths =========\n",
    "CONFIG ='C:/Users/heheh/mmdetection/configs/mask_rcnn/mask-rcnn_r50_fpn_1x_coco.py'\n",
    "CHECKPOINT = 'C:/Users/heheh/mmdetection/checkpoints/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth'\n",
    "DATA_ROOT = 'C:/Users/heheh/mmdetection/data/coco'\n",
    "ANN_FILE  = os.path.join(DATA_ROOT, 'annotations', 'instances_val2017.json')\n",
    "IMG_DIR   = os.path.join(DATA_ROOT, 'val2017')\n",
    "ADV_SAVE_DIR = os.path.join(DATA_ROOT, 'instance_maskrcnn_adv')\n",
    "os.makedirs(ADV_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ========= Attack hyperparams (pixel-space) =========\n",
    "epsilon = 8/255.0     # L_inf epsilon in [0,1] space\n",
    "alpha   = 2/255.0     # step size in [0,1]\n",
    "num_steps = 20\n",
    "\n",
    "# ========= 1) Build runner/model + dataloader =========\n",
    "cfg = Config.fromfile(CONFIG)\n",
    "cfg.default_scope = 'mmdet'\n",
    "cfg.load_from = CHECKPOINT\n",
    "cfg.work_dir = './work_dirs/pgd_adv_eval'\n",
    "\n",
    "# Point the test dataset to COCO val\n",
    "test_dataset = cfg.test_dataloader.dataset\n",
    "test_dataset.type = 'CocoDataset'\n",
    "test_dataset.data_root = DATA_ROOT\n",
    "test_dataset.ann_file = ANN_FILE\n",
    "test_dataset.data_prefix = dict(img=IMG_DIR)\n",
    "test_dataset.test_mode = True\n",
    "\n",
    "# optional: limit to first N images while debugging\n",
    "# test_dataset.indices = list(range(20))\n",
    "\n",
    "# Evaluator (keep if you want to also report metrics on adv images later)\n",
    "cfg.test_evaluator = dict(type='CocoMetric', ann_file=ANN_FILE, metric=['bbox','segm'])\n",
    "\n",
    "# Visualizer (avoid empty list crash)\n",
    "if hasattr(cfg, 'visualizer'):\n",
    "    cfg.visualizer.vis_backends = None\n",
    "\n",
    "runner = Runner.from_cfg(cfg)\n",
    "model = runner.model\n",
    "model.eval()\n",
    "device = next(model.parameters()).device\n",
    "\n",
    "# ========= 2) Utility: convert pixel-space eps/alpha to normalized space =========\n",
    "# MMDet defaults use mean/std in 0-255 scale.\n",
    "preproc = model.data_preprocessor\n",
    "mean = torch.tensor(preproc.mean, device=device).view(1,3,1,1)      # shape (1,C,1,1)\n",
    "std  = torch.tensor(preproc.std,  device=device).view(1,3,1,1)\n",
    "\n",
    "# bounds in normalized space for [0,255] pixel range:\n",
    "lower = (0.0 - mean) / std\n",
    "upper = (255.0 - mean) / std\n",
    "\n",
    "# pixel-space eps -> normalized-space eps (per channel)\n",
    "eps_norm   = (epsilon * 255.0) / std\n",
    "alpha_norm = (alpha   * 255.0) / std\n",
    "\n",
    "# ========= 3) DataLoader (use same as test) =========\n",
    "test_loader = runner.build_dataloader(cfg.test_dataloader)\n",
    "\n",
    "# ========= 4) PGD loop per image and SAVE =========\n",
    "def total_loss_sum(losses):\n",
    "    \"\"\"Sum all tensors in the nested dict returned by model(..., mode='loss').\"\"\"\n",
    "    total = 0.0\n",
    "    for v in losses.values():\n",
    "        if isinstance(v, dict):\n",
    "            for vv in v.values():\n",
    "                if torch.is_tensor(vv):\n",
    "                    total = total + vv.sum()\n",
    "        elif torch.is_tensor(v):\n",
    "            total = total + v.sum()\n",
    "    return total\n",
    "\n",
    "@torch.no_grad()\n",
    "def save_adv_in_original_size(norm_img, ds, save_path):\n",
    "    \"\"\"\n",
    "    norm_img: (1,3,H_pad,W_pad) normalized tensor ((img-mean)/std) in the model space\n",
    "    ds:       DetDataSample for this image (contains ori/img/pad shapes)\n",
    "    Saves an RGB image at the original size (ori_w, ori_h).\n",
    "    \"\"\"\n",
    "    # 1) denorm back to 0..255\n",
    "    x = norm_img.clone() * std + mean            # (1,3,H,W) in 0..255\n",
    "    x = x.clamp(0, 255)[0].permute(1, 2, 0).cpu().numpy().astype(np.uint8)  # (H,W,3)\n",
    "\n",
    "    # 2) crop padding (keep only real img region)\n",
    "    img_h, img_w = ds.metainfo['img_shape'][:2]   # after resize, before pad\n",
    "    x = x[:img_h, :img_w, :]                      # remove bottom/right pad\n",
    "\n",
    "    # 3) resize back to original size\n",
    "    ori_h, ori_w = ds.metainfo['ori_shape'][:2]\n",
    "    pil = Image.fromarray(x)                      # x is RGB here\n",
    "    pil = pil.resize((ori_w, ori_h), resample=Image.BILINEAR)\n",
    "\n",
    "    # 4) save\n",
    "    pil.save(save_path, quality=95)\n",
    "\n",
    "# Enable grads inside loop\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "for batch in test_loader:\n",
    "    # batch is a dict with 'inputs' (list of tensors) and 'data_samples' (list of DetDataSample)\n",
    "    # Preprocessor already ran in DataLoader collate -> inputs are normalized tensors on device after model.data_preprocessor?\n",
    "    # In test loader, they are raw; we must preprocess using model.data_preprocessor manually:\n",
    "    data = model.data_preprocessor(batch, training=False)  # returns dict with 'inputs' tensor and 'data_samples' list\n",
    "\n",
    "    inputs = data['inputs']            # Tensor (N,C,H,W), normalized with mean/std\n",
    "    data_samples = data['data_samples']  # list of DetDataSample with metainfo set\n",
    "    N = inputs.shape[0]\n",
    "\n",
    "    # Process images one-by-one (simpler to keep filenames, shapes consistent)\n",
    "    for i in range(N):\n",
    "        img = inputs[i:i+1].detach().clone().to(device)  # (1,C,H,W) normalized\n",
    "        ds  = [data_samples[i]]  # list with one sample\n",
    "\n",
    "        # Get a filename to save under\n",
    "        img_name = ds[0].metainfo.get('img_path', None)\n",
    "        if img_name is None:\n",
    "            # fallback to ori_filename if available\n",
    "            img_name = ds[0].metainfo.get('ori_filename', f'idx_{ds[0].metainfo.get(\"img_id\",\"unk\")}.jpg')\n",
    "        base = os.path.splitext(os.path.basename(img_name))[0]\n",
    "        save_path = os.path.join(ADV_SAVE_DIR, f'{base}.jpg')\n",
    "\n",
    "        # Initialize adv as the clean normalized image\n",
    "        x_adv = img.clone().detach()\n",
    "        x_adv.requires_grad_(True)\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            # Make sure metainfo shapes reflect current tensor size\n",
    "            H, W = x_adv.shape[2], x_adv.shape[3]\n",
    "            ds[0].set_metainfo({\n",
    "                'img_shape': (H, W, 3),\n",
    "                'pad_shape': (H, W, 3),\n",
    "                'batch_input_shape': (H, W)\n",
    "            })\n",
    "\n",
    "            # Zero model grads; keep only x_adv gradient\n",
    "            model.zero_grad(set_to_none=True)\n",
    "\n",
    "            # Forward in \"loss\" mode\n",
    "            losses = model(x_adv, ds, mode='loss')                                                                                                          \n",
    "            loss = total_loss_sum(losses)\n",
    "            loss.backward()\n",
    "\n",
    "            # PGD update in normalized space\n",
    "            with torch.no_grad():\n",
    "                grad = x_adv.grad\n",
    "                x_adv = x_adv + alpha_norm * torch.sign(grad)                       \n",
    "                # Project back to the L_inf ball around original img\n",
    "                x_adv = torch.max(torch.min(x_adv, img + eps_norm), img - eps_norm)\n",
    "                # Clamp to valid normalized range\n",
    "                x_adv = torch.max(torch.min(x_adv, upper), lower)\n",
    "\n",
    "            x_adv.requires_grad_(True)\n",
    "                              \n",
    "        # Save adv image (denormalize to 0..255 and write PNG)\n",
    "        with torch.no_grad():\n",
    "            save_adv_in_original_size(x_adv, ds[0], save_path)\n",
    "\n",
    "        print(f'[PGD] Saved: {save_path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
