{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a347ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PGD for PanopticFPN (MMDetection 3.x)\n",
    "import os, copy, torch, numpy as np\n",
    "from PIL import Image\n",
    "from mmengine.config import Config\n",
    "from mmengine.runner import Runner\n",
    "from mmengine.runner.checkpoint import load_checkpoint\n",
    "\n",
    "# ====== Paths ======\n",
    "CONFIG = r'C:/Users/heheh/mmdetection/configs/panoptic_fpn/panoptic-fpn_r50_fpn_1x_coco.py'\n",
    "CHECKPOINT = r'C:/Users/heheh/mmdetection/checkpoints/panoptic_fpn_r50_fpn_1x_coco_20210821_101153-9668fd13.pth'\n",
    "DATA_ROOT = r'C:/Users/heheh/mmdetection/data/coco'\n",
    "PAN_JSON  = os.path.join(DATA_ROOT, 'annotations', 'panoptic_val2017.json')\n",
    "IMG_DIR   = os.path.join(DATA_ROOT, 'val2017')\n",
    "PAN_SEG   = os.path.join(DATA_ROOT, 'annotations', 'panoptic_val2017')  # PNG dir\n",
    "ADV_SAVE_DIR = os.path.join(DATA_ROOT, 'panoptic_fpn_adv')\n",
    "os.makedirs(ADV_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ====== Attack hyperparams (pixel-space) ======\n",
    "epsilon   = 8/255.0           # L_inf radius\n",
    "alpha     = 2/255.0           # step size\n",
    "num_steps = 20\n",
    "random_start = True           # good for stronger attacks\n",
    "\n",
    "# ====== Build model ======\n",
    "cfg = Config.fromfile(CONFIG)\n",
    "cfg.default_scope = 'mmdet'\n",
    "cfg.load_from = CHECKPOINT\n",
    "cfg.work_dir = './work_dirs/pgd_panoptic'\n",
    "if hasattr(cfg, 'visualizer'):\n",
    "    cfg.visualizer.vis_backends = None\n",
    "\n",
    "runner = Runner.from_cfg(cfg)\n",
    "model = runner.model\n",
    "model.eval()\n",
    "device = next(model.parameters()).device\n",
    "# Ensure weights are loaded for ad-hoc usage:\n",
    "load_checkpoint(model, CHECKPOINT, map_location=device)\n",
    "model.cfg = cfg  # handy, if you later use APIs that expect .cfg\n",
    "\n",
    "# ====== Build an ATTACK dataloader WITH GT (test_mode=False) ======\n",
    "# Use the training pipeline (loads bboxes/masks/sem seg) but point to VAL panoptic\n",
    "attack_dl_cfg = copy.deepcopy(cfg.train_dataloader)\n",
    "ds = attack_dl_cfg.dataset\n",
    "# If your train_dataloader wraps the dataset (e.g., RepeatDataset), unwrap to the innermost:\n",
    "while hasattr(ds, 'dataset'):\n",
    "    ds = ds.dataset\n",
    "ds.type = 'CocoPanopticDataset'\n",
    "ds.data_root = DATA_ROOT\n",
    "ds.ann_file = PAN_JSON\n",
    "ds.data_prefix = dict(img=IMG_DIR, seg=PAN_SEG)  # img dir + GT panoptic PNG dir\n",
    "ds.test_mode = False  # IMPORTANT: include ground-truth for losses\n",
    "\n",
    "# Keep batch size 1 (simplifies per-image saving & metadata handling)\n",
    "attack_dl_cfg.batch_size = 1\n",
    "attack_dl_cfg.num_workers = 2\n",
    "\n",
    "attack_loader = runner.build_dataloader(attack_dl_cfg)\n",
    "\n",
    "# ====== Normalization bounds (model uses mean/std in 0-255 space) ======\n",
    "pre = model.data_preprocessor\n",
    "mean = torch.tensor(pre.mean, device=device).view(1,3,1,1)\n",
    "std  = torch.tensor(pre.std,  device=device).view(1,3,1,1)\n",
    "lower = (0.0   - mean) / std\n",
    "upper = (255.0 - mean) / std\n",
    "\n",
    "eps_norm   = (epsilon * 255.0) / std\n",
    "alpha_norm = (alpha   * 255.0) / std\n",
    "\n",
    "# ====== Utilities ======\n",
    "def sum_all_losses(losses: dict):\n",
    "    total = 0.0\n",
    "    for v in losses.values():\n",
    "        if isinstance(v, dict):\n",
    "            for t in v.values():\n",
    "                if torch.is_tensor(t):\n",
    "                    total = total + t.sum()\n",
    "        elif torch.is_tensor(v):\n",
    "            total = total + v.sum()\n",
    "    return total\n",
    "\n",
    "@torch.no_grad()\n",
    "def save_adv_in_original_size(norm_img_1CHW, data_sample, save_path):\n",
    "    \"\"\"Denorm -> unpad -> resize back to ori size -> save\"\"\"\n",
    "    x = norm_img_1CHW.clone() * std + mean        # 0..255\n",
    "    x = x.clamp(0,255)[0].permute(1,2,0).cpu().numpy().astype(np.uint8)  # HxWx3\n",
    "\n",
    "    img_h, img_w = data_sample.metainfo['img_shape'][:2]   # after resize, before pad\n",
    "    x = x[:img_h, :img_w, :]                               # remove pad\n",
    "\n",
    "    ori_h, ori_w = data_sample.metainfo['ori_shape'][:2]\n",
    "    Image.fromarray(x).resize((ori_w, ori_h), Image.BILINEAR).save(save_path, quality=95)\n",
    "\n",
    "# ====== PGD loop ======\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "for data_batch in attack_loader:\n",
    "    # Normalize & collate like the runner would\n",
    "    data = model.data_preprocessor(data_batch, training=False)  # {'inputs': tensor, 'data_samples': list}\n",
    "    imgs = data['inputs']             # (1,3,H,W), normalized\n",
    "    samples = data['data_samples']    # [DetDataSample] with GT for panoptic (instances + semantic)\n",
    "\n",
    "    x = imgs.detach().clone().to(device)       # clean normalized\n",
    "    if random_start:\n",
    "        x = x + torch.empty_like(x).uniform_(-1,1) * eps_norm\n",
    "        x = torch.max(torch.min(x, x + eps_norm), x - eps_norm)  # stay in ball\n",
    "        x = torch.max(torch.min(x, upper), lower)                # valid range\n",
    "\n",
    "    x.requires_grad_(True)\n",
    "\n",
    "    # Derive a good filename\n",
    "    meta = samples[0].metainfo\n",
    "    base = os.path.splitext(os.path.basename(meta.get('ori_filename', meta.get('img_path', 'img'))))[0]\n",
    "    save_path = os.path.join(ADV_SAVE_DIR, f'{base}.jpg')\n",
    "\n",
    "    for t in range(num_steps):\n",
    "        H, W = x.shape[2], x.shape[3]\n",
    "        samples[0].set_metainfo({\n",
    "            'img_shape': (H, W, 3),\n",
    "            'pad_shape': (H, W, 3),\n",
    "            'batch_input_shape': (H, W),\n",
    "        })\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        losses = model(x, samples, mode='loss')   # PanopticFPN: RPN/ROI + semantic head losses\n",
    "        loss = sum_all_losses(losses)\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            grad = x.grad\n",
    "            x = x + alpha_norm * torch.sign(grad)           # untargeted: maximize total loss\n",
    "            x = torch.max(torch.min(x, imgs + eps_norm), imgs - eps_norm)  # project to L_inf ball\n",
    "            x = torch.max(torch.min(x, upper), lower)       # clamp valid range\n",
    "\n",
    "        x.requires_grad_(True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        save_adv_in_original_size(x, samples[0], save_path)\n",
    "    print(f'[PGD PanopticFPN] Saved {save_path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
