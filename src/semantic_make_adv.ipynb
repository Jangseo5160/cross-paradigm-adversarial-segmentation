{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0257306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PGD for MMDetection 3.x (DeeplabV3, COCO)\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "\n",
    "import mmseg\n",
    "from mmengine.config import Config\n",
    "from mmseg.utils import register_all_modules\n",
    "from mmseg.apis import init_model\n",
    "\n",
    "###############################################################################\n",
    "# 1. Basic Setup\n",
    "###############################################################################\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[INFO] Using device: {device}\")\n",
    "\n",
    "CONFIG_FILE = 'C:/Users/heheh/mmsegmentation/configs/deeplabv3/deeplabv3_r50-d8_4xb4-80k_coco-stuff164k-512x512.py'\n",
    "CHECKPOINT_FILE = 'C:/Users/heheh/mmsegmentation/checkpoints/deeplabv3_r50-d8_512x512_4x4_80k_coco-stuff164k_20210709_163016-88675c24.pth'\n",
    "IMAGE_DIR = \"C:/Users/heheh/val2017/val2017\"\n",
    "MASK_DIR = \"C:/Users/heheh/mmsegmentation/data/coco_stuff164k/annotations/val2017\"\n",
    "ADV_SAVE_DIR = \"C:/Users/heheh/mmsegmentation/data/semantic_adv_deeplabv3_2\"\n",
    "\n",
    "NUM_CLASSES = 171\n",
    "IMAGE_HEIGHT = 512\n",
    "IMAGE_WIDTH = 512\n",
    "IGNORE_INDEX = 255\n",
    "\n",
    "# COCO-Stuff label mapping\n",
    "COCO_STUFF_LABEL_MAP = {\n",
    "    0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10,\n",
    "    11: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16, 18: 17, 19: 18, 20: 19, 21: 20,\n",
    "    22: 21, 23: 22, 24: 23, 25: 24, 27: 25, 28: 26, 31: 27, 32: 28, 33: 29, 34: 30,\n",
    "    35: 31, 36: 32, 37: 33, 38: 34, 39: 35, 40: 36, 41: 37, 42: 38, 43: 39, 44: 40,\n",
    "    46: 41, 47: 42, 48: 43, 49: 44, 50: 45, 51: 46, 52: 47, 53: 48, 54: 49, 55: 50,\n",
    "    56: 51, 57: 52, 58: 53, 59: 54, 60: 55, 61: 56, 62: 57, 63: 58, 64: 59, 65: 60,\n",
    "    67: 61, 70: 62, 72: 63, 73: 64, 74: 65, 75: 66, 76: 67, 77: 68, 78: 69, 79: 70,\n",
    "    80: 71, 81: 72, 82: 73, 84: 74, 85: 75, 86: 76, 87: 77, 88: 78, 89: 79, 90: 80,\n",
    "    92: 81, 93: 82, 94: 83, 95: 84, 96: 85, 97: 86, 98: 87, 99: 88, 100: 89, 101: 90,\n",
    "    102: 91, 103: 92, 104: 93, 105: 94, 106: 95, 107: 96, 108: 97, 109: 98, 110: 99, 111: 100,\n",
    "    112: 101, 113: 102, 114: 103, 115: 104, 116: 105, 117: 106, 118: 107, 119: 108, 120: 109, 121: 110,\n",
    "    122: 111, 123: 112, 124: 113, 125: 114, 126: 115, 127: 116, 128: 117, 129: 118, 130: 119, 131: 120,\n",
    "    132: 121, 133: 122, 134: 123, 135: 124, 136: 125, 137: 126, 138: 127, 139: 128, 140: 129, 141: 130,\n",
    "    142: 131, 143: 132, 144: 133, 145: 134, 146: 135, 147: 136, 148: 137, 149: 138, 150: 139, 151: 140,\n",
    "    152: 141, 153: 142, 154: 143, 155: 144, 156: 145, 157: 146, 158: 147, 159: 148, 160: 149, 161: 150,\n",
    "    162: 151, 163: 152, 164: 153, 165: 154, 166: 155, 167: 156, 168: 157, 169: 158, 170: 159, 171: 160,\n",
    "    172: 161, 173: 162, 174: 163, 175: 164, 176: 165, 177: 166, 178: 167, 179: 168, 180: 169, 181: 170,\n",
    "    182: 171, 255: 255\n",
    "}\n",
    "\n",
    "###############################################################################\n",
    "# 2. COCO Dataset (원본 사이즈 저장 기능 추가)\n",
    "###############################################################################\n",
    "def get_all_files(image_dir, mask_dir, img_exts=('.jpg', '.jpeg', '.png')):\n",
    "    \"\"\"이미지-마스크 쌍이 존재하는 파일들만 반환\"\"\"\n",
    "    files = sorted([f for f in os.listdir(image_dir) if f.endswith(img_exts)])\n",
    "    return [f for f in files if os.path.exists(os.path.join(mask_dir, f.rsplit('.', 1)[0] + '.png'))]\n",
    "\n",
    "class COCODataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, max_images=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        \n",
    "        self.file_list = get_all_files(image_dir, mask_dir)\n",
    "        if max_images:\n",
    "            self.file_list = self.file_list[:max_images]\n",
    "        \n",
    "        print(f\"[INFO] Found {len(self.file_list)} valid image-mask pairs\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.file_list[idx]\n",
    "        img_path = os.path.join(self.image_dir, fname)\n",
    "        mask_path = os.path.join(self.mask_dir, fname.rsplit('.', 1)[0] + '.png')\n",
    "\n",
    "        # Load original image and get original size\n",
    "        original_image = Image.open(img_path).convert(\"RGB\")\n",
    "        original_size = original_image.size  # (width, height)\n",
    "\n",
    "        # Resize for model processing\n",
    "        image = original_image.resize((IMAGE_WIDTH, IMAGE_HEIGHT), Image.BILINEAR)\n",
    "        image = np.array(image, dtype=np.float32)\n",
    "\n",
    "        # Load and resize mask\n",
    "        mask = Image.open(mask_path)\n",
    "        mask = mask.resize((IMAGE_WIDTH, IMAGE_HEIGHT), Image.NEAREST)\n",
    "        mask = np.array(mask, dtype=np.uint8)\n",
    "\n",
    "        # Apply label mapping\n",
    "        mapped_mask = np.full_like(mask, fill_value=255, dtype=np.uint8)\n",
    "        for original_label, mapped_label in COCO_STUFF_LABEL_MAP.items():\n",
    "            mapped_mask[mask == original_label] = mapped_label\n",
    "\n",
    "        # Normalize image\n",
    "        mean = np.array([123.675, 116.28, 103.53]).reshape(1, 1, 3)\n",
    "        std = np.array([58.395, 57.12, 57.375]).reshape(1, 1, 3)\n",
    "        image = (image - mean) / std\n",
    "        image = image.transpose(2, 0, 1)  # (C,H,W)\n",
    "\n",
    "        # Convert to tensors\n",
    "        image_tensor = torch.from_numpy(image).float()\n",
    "        mask_tensor = torch.from_numpy(mapped_mask).long()\n",
    "        \n",
    "        return image_tensor, mask_tensor, fname, original_size\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"Custom collate function to handle original_size as non-tensor\"\"\"\n",
    "    images, masks, filenames, original_sizes = zip(*batch)\n",
    "    \n",
    "    # Tensor로 변환할 것들\n",
    "    images = torch.stack(images)\n",
    "    masks = torch.stack(masks)\n",
    "    \n",
    "    # Tensor로 변환하지 않을 것들 (튜플로 유지)\n",
    "    filenames = list(filenames)\n",
    "    original_sizes = list(original_sizes)  # tuple로 유지\n",
    "    \n",
    "    return images, masks, filenames, original_sizes\n",
    "\n",
    "def get_dataloader(image_dir, mask_dir, batch_size=1, max_images=None):\n",
    "    dataset = COCODataset(image_dir, mask_dir, max_images)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        collate_fn=custom_collate_fn  # 추가\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "###############################################################################\n",
    "# 3. Model Loading\n",
    "###############################################################################\n",
    "def load_deeplabv3_model():\n",
    "    \"\"\"DeepLabV3 모델 로드\"\"\"\n",
    "    register_all_modules()\n",
    "    \n",
    "    cfg = Config.fromfile(CONFIG_FILE)\n",
    "    cfg.model.pretrained = None\n",
    "    cfg.model.train_cfg = None\n",
    "    \n",
    "    if \"test_cfg\" in cfg.model and cfg.model.test_cfg is not None:\n",
    "        cfg.model.test_cfg.mode = \"whole\"\n",
    "\n",
    "    model = init_model(cfg, checkpoint=CHECKPOINT_FILE, device=device)\n",
    "    model.eval()\n",
    "    print(f\"[INFO] Loaded DeepLabV3 model on device: {device}\")\n",
    "    return model\n",
    "\n",
    "###############################################################################\n",
    "# 4. PGD Attack Function\n",
    "###############################################################################\n",
    "def get_model_output(model, x, return_logits=False):\n",
    "    \"\"\"모델 출력 얻기\"\"\"\n",
    "    x = x.to(device, dtype=torch.float32, non_blocking=True)\n",
    "    with torch.no_grad():\n",
    "        outs = model(x, mode=\"tensor\")\n",
    "\n",
    "    if isinstance(outs, torch.Tensor):\n",
    "        pass\n",
    "    elif isinstance(outs, (list, tuple)) and len(outs) > 0:\n",
    "        outs = outs[0]\n",
    "    elif isinstance(outs, dict) and \"logits\" in outs:\n",
    "        outs = outs[\"logits\"]\n",
    "    else:\n",
    "        raise TypeError(f\"Unexpected output type: {type(outs)}\")\n",
    "\n",
    "    outs = F.interpolate(outs, size=(IMAGE_HEIGHT, IMAGE_WIDTH), mode=\"bilinear\", align_corners=False)\n",
    "    \n",
    "    if return_logits:\n",
    "        return outs\n",
    "    else:\n",
    "        return outs.argmax(dim=1)\n",
    "\n",
    "def pgd_attack(model, images, labels, epsilon, alpha, num_steps, ignore_index=255):\n",
    "    \"\"\"PGD 공격\"\"\"\n",
    "    images = images.clone().detach().to(device, dtype=torch.float32)\n",
    "    labels = labels.clone().detach().to(device)\n",
    "    delta = torch.zeros_like(images, requires_grad=True)\n",
    "\n",
    "    mean = torch.tensor([123.675, 116.28, 103.53]).view(1, 3, 1, 1).to(device, dtype=torch.float32)\n",
    "    std = torch.tensor([58.395, 57.12, 57.375]).view(1, 3, 1, 1).to(device, dtype=torch.float32)\n",
    "    min_vals = (0 - mean) / std\n",
    "    max_vals = (255 - mean) / std\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        outs = model(images + delta, mode=\"tensor\")\n",
    "        if isinstance(outs, list):\n",
    "            outs = outs[0]\n",
    "        elif isinstance(outs, dict) and \"logits\" in outs:\n",
    "            outs = outs[\"logits\"]\n",
    "\n",
    "        outs = F.interpolate(outs, size=labels.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        loss = F.cross_entropy(outs, labels, ignore_index=ignore_index)\n",
    "        loss.backward()\n",
    "\n",
    "        grad = delta.grad.detach()\n",
    "        delta.data.add_(alpha * torch.sign(grad))\n",
    "        delta.data.clamp_(-epsilon, epsilon)\n",
    "        delta.data = torch.min(torch.max(images + delta.data, min_vals), max_vals) - images\n",
    "        delta.grad.zero_()\n",
    "        delta.requires_grad = True\n",
    "\n",
    "    adv = torch.clamp(images + delta, min_vals, max_vals)\n",
    "    return adv.detach()\n",
    "\n",
    "###############################################################################\n",
    "# 5. Image Saving Functions (원본 사이즈로 .jpg 저장)\n",
    "###############################################################################\n",
    "def denormalize_image(tensor_img):\n",
    "    \"\"\"정규화된 텐서를 원본 이미지로 변환\"\"\"\n",
    "    mean = torch.tensor([123.675, 116.28, 103.53]).view(1, 3, 1, 1).to(tensor_img.device)\n",
    "    std = torch.tensor([58.395, 57.12, 57.375]).view(1, 3, 1, 1).to(tensor_img.device)\n",
    "    \n",
    "    denorm = tensor_img * std + mean\n",
    "    denorm = torch.clamp(denorm, 0, 255)\n",
    "    return denorm\n",
    "\n",
    "def save_adversarial_image_with_original_size(adv_tensor, filename, original_size, save_dir):\n",
    "    \"\"\"Adversarial 이미지를 원본 사이즈 .jpg 형태로 저장\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Denormalize and convert to numpy\n",
    "    denorm = denormalize_image(adv_tensor)\n",
    "    img_np = denorm[0].cpu().numpy().transpose(1, 2, 0).astype(np.uint8)\n",
    "    \n",
    "    # Convert to PIL\n",
    "    img_pil = Image.fromarray(img_np)\n",
    "    \n",
    "    # Resize back to original size\n",
    "    img_pil = img_pil.resize(original_size, Image.BILINEAR)\n",
    "    \n",
    "    # Change extension to .jpg and save\n",
    "    base_name = os.path.splitext(filename)[0]\n",
    "    jpg_filename = base_name + '.jpg'\n",
    "    save_path = os.path.join(save_dir, jpg_filename)\n",
    "    \n",
    "    # Save as JPEG with high quality\n",
    "    img_pil.save(save_path, 'JPEG', quality=95)\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "###############################################################################\n",
    "# 6. Evaluation Metrics\n",
    "###############################################################################\n",
    "def compute_miou(pred, target, num_classes, ignore_index=255):\n",
    "    \"\"\"mIoU 계산\"\"\"\n",
    "    ious = []\n",
    "    for cls in range(num_classes):\n",
    "        pred_mask = (pred == cls)\n",
    "        target_mask = (target == cls)\n",
    "        \n",
    "        if ignore_index is not None:\n",
    "            valid_mask = (target != ignore_index)\n",
    "            pred_mask = pred_mask & valid_mask\n",
    "            target_mask = target_mask & valid_mask\n",
    "        \n",
    "        intersection = (pred_mask & target_mask).sum()\n",
    "        union = (pred_mask | target_mask).sum()\n",
    "        \n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))\n",
    "        else:\n",
    "            ious.append(float(intersection) / float(union))\n",
    "    \n",
    "    return np.nanmean(ious)\n",
    "\n",
    "def compute_pixel_accuracy(pred, target, ignore_index=255):\n",
    "    \"\"\"Pixel Accuracy 계산\"\"\"\n",
    "    if ignore_index is not None:\n",
    "        valid_mask = (target != ignore_index)\n",
    "        pred_valid = pred[valid_mask]\n",
    "        target_valid = target[valid_mask]\n",
    "    else:\n",
    "        pred_valid = pred\n",
    "        target_valid = target\n",
    "    \n",
    "    if len(pred_valid) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return float((pred_valid == target_valid).sum()) / len(pred_valid)\n",
    "\n",
    "def compute_attack_success_rate(pred_clean, pred_adv, target, ignore_index=255):\n",
    "    \"\"\"Attack Success Rate 계산\"\"\"\n",
    "    if ignore_index is not None:\n",
    "        valid_mask = (target != ignore_index)\n",
    "        pred_clean_valid = pred_clean[valid_mask]\n",
    "        pred_adv_valid = pred_adv[valid_mask]\n",
    "        target_valid = target[valid_mask]\n",
    "    else:\n",
    "        pred_clean_valid = pred_clean\n",
    "        pred_adv_valid = pred_adv\n",
    "        target_valid = target\n",
    "    \n",
    "    if len(pred_clean_valid) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    correct_clean = (pred_clean_valid == target_valid)\n",
    "    incorrect_adv = (pred_adv_valid != target_valid)\n",
    "    \n",
    "    success = (correct_clean & incorrect_adv).sum()\n",
    "    return float(success) / len(pred_clean_valid)\n",
    "\n",
    "###############################################################################\n",
    "# 7. Main Functions (PGD만 수행)\n",
    "###############################################################################\n",
    "def generate_and_save_pgd_images(model, dataloader, save_dir, **attack_params):\n",
    "    \"\"\"PGD adversarial 이미지들을 생성하고 저장\"\"\"\n",
    "    print(f\"\\n[INFO] Generating PGD adversarial images...\")\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    saved_files = []\n",
    "    \n",
    "    for batch_idx, (images, labels, filenames, original_sizes) in enumerate(tqdm(dataloader, desc=\"Generating PGD\")):\n",
    "        images = images.to(device, dtype=torch.float32)\n",
    "        labels = labels.to(device, dtype=torch.long)\n",
    "        \n",
    "        # Generate adversarial images using PGD\n",
    "        adv_images = pgd_attack(model, images, labels, **attack_params)\n",
    "        \n",
    "        # Save each image in the batch with original size\n",
    "        for i, (filename, original_size) in enumerate(zip(filenames, original_sizes)):\n",
    "            save_path = save_adversarial_image_with_original_size(adv_images[i:i+1], filename, original_size, save_dir)\n",
    "            saved_files.append((filename, save_path))\n",
    "    \n",
    "    print(f\"[INFO] Saved {len(saved_files)} PGD images to {save_dir}\")\n",
    "    return saved_files\n",
    "\n",
    "def evaluate_pgd_images(model, clean_dataloader, adv_save_dir):\n",
    "    \"\"\"저장된 PGD adversarial 이미지들을 평가\"\"\"\n",
    "    print(f\"\\n[INFO] Evaluating PGD adversarial images...\")\n",
    "    \n",
    "    results = {\n",
    "        'pixel_accuracy': [],\n",
    "        'miou': [],\n",
    "        'attack_success_rate': []\n",
    "    }\n",
    "    \n",
    "    for batch_idx, (clean_images, labels, filenames, original_sizes) in enumerate(tqdm(clean_dataloader, desc=\"Evaluating PGD\")):\n",
    "        clean_images = clean_images.to(device, dtype=torch.float32)\n",
    "        labels = labels.to(device, dtype=torch.long)\n",
    "        \n",
    "        # Load adversarial images\n",
    "        adv_images_list = []\n",
    "        valid_indices = []\n",
    "        \n",
    "        for i, filename in enumerate(filenames):\n",
    "            base_name = os.path.splitext(filename)[0]\n",
    "            adv_filename = base_name + '.jpg'\n",
    "            adv_path = os.path.join(adv_save_dir, adv_filename)\n",
    "            \n",
    "            if os.path.exists(adv_path):\n",
    "                adv_img = Image.open(adv_path).convert(\"RGB\")\n",
    "                adv_img = adv_img.resize((IMAGE_WIDTH, IMAGE_HEIGHT), Image.BILINEAR)\n",
    "                adv_img = np.array(adv_img, dtype=np.float32)\n",
    "                \n",
    "                # Normalize\n",
    "                mean = np.array([123.675, 116.28, 103.53]).reshape(1, 1, 3)\n",
    "                std = np.array([58.395, 57.12, 57.375]).reshape(1, 1, 3)\n",
    "                adv_img = (adv_img - mean) / std\n",
    "                adv_img = adv_img.transpose(2, 0, 1)\n",
    "                adv_images_list.append(adv_img)\n",
    "                valid_indices.append(i)\n",
    "            else:\n",
    "                print(f\"[WARN] Adversarial image not found: {adv_path}\")\n",
    "        \n",
    "        if not adv_images_list:\n",
    "            continue\n",
    "            \n",
    "        adv_images = torch.stack([torch.from_numpy(img) for img in adv_images_list]).to(device, dtype=torch.float32)\n",
    "        \n",
    "        # Filter clean images and labels for valid indices\n",
    "        clean_images_valid = clean_images[valid_indices]\n",
    "        labels_valid = labels[valid_indices]\n",
    "        \n",
    "        # Get predictions\n",
    "        with torch.no_grad():\n",
    "            pred_clean = get_model_output(model, clean_images_valid)\n",
    "            pred_adv = get_model_output(model, adv_images)\n",
    "        \n",
    "        # Calculate metrics for each valid image\n",
    "        for i in range(len(labels_valid)):\n",
    "            pred_clean_np = pred_clean[i].cpu().numpy()\n",
    "            pred_adv_np = pred_adv[i].cpu().numpy()\n",
    "            label_np = labels_valid[i].cpu().numpy()\n",
    "            \n",
    "            # Pixel accuracy\n",
    "            acc = compute_pixel_accuracy(pred_adv_np, label_np, IGNORE_INDEX)\n",
    "            results['pixel_accuracy'].append(acc)\n",
    "            \n",
    "            # mIoU\n",
    "            miou = compute_miou(pred_adv_np, label_np, NUM_CLASSES, IGNORE_INDEX)\n",
    "            results['miou'].append(miou)\n",
    "            \n",
    "            # Attack success rate\n",
    "            asr = compute_attack_success_rate(pred_clean_np, pred_adv_np, label_np, IGNORE_INDEX)\n",
    "            results['attack_success_rate'].append(asr)\n",
    "    \n",
    "    # Calculate averages\n",
    "    avg_results = {}\n",
    "    for key, values in results.items():\n",
    "        if values:\n",
    "            avg_results[f'avg_{key}'] = np.mean(values)\n",
    "            avg_results[f'std_{key}'] = np.std(values)\n",
    "        else:\n",
    "            avg_results[f'avg_{key}'] = 0.0\n",
    "            avg_results[f'std_{key}'] = 0.0\n",
    "    \n",
    "    return avg_results\n",
    "\n",
    "def main():\n",
    "    \"\"\"메인 함수 - PGD만 수행\"\"\"\n",
    "    # 1. Load model\n",
    "    model = load_deeplabv3_model()\n",
    "    \n",
    "    # 2. Prepare dataloader (10개 이미지로 빠른 테스트)\n",
    "    test_loader = get_dataloader(IMAGE_DIR, MASK_DIR, batch_size=1, max_images=5000)\n",
    "    \n",
    "    # 3. PGD attack parameters\n",
    "    std_tensor = torch.tensor([58.395, 57.12, 57.375]).view(1, 3, 1, 1).to(device)\n",
    "    epsilon = (8.0 / std_tensor)  # 8/255 in normalized space\n",
    "    alpha = (2.0 / std_tensor)    # 2/255 in normalized space\n",
    "    num_steps = 20\n",
    "    \n",
    "    pgd_params = {\n",
    "        \"epsilon\": epsilon,\n",
    "        \"alpha\": alpha,\n",
    "        \"num_steps\": num_steps,\n",
    "        \"ignore_index\": IGNORE_INDEX\n",
    "    }\n",
    "    \n",
    "    # 4. Generate and save PGD adversarial images\n",
    "    pgd_save_dir = os.path.join(ADV_SAVE_DIR, \"pgd\")\n",
    "    saved_files = generate_and_save_pgd_images(model, test_loader, pgd_save_dir, **pgd_params)\n",
    "    \n",
    "    # 5. Evaluate the saved PGD images\n",
    "    results = evaluate_pgd_images(model, test_loader, pgd_save_dir)\n",
    "    \n",
    "    # 6. Add attack info to results\n",
    "    results['attack_name'] = 'PGD'\n",
    "    results['num_images'] = len(saved_files)\n",
    "    results['save_directory'] = pgd_save_dir\n",
    "    \n",
    "    # 7. Print results\n",
    "    print(f\"\\n[RESULT] PGD Results (10 test images):\")\n",
    "    print(f\"  Pixel Accuracy: {results['avg_pixel_accuracy']:.4f} ± {results['std_pixel_accuracy']:.4f}\")\n",
    "    print(f\"  mIoU: {results['avg_miou']:.4f} ± {results['std_miou']:.4f}\")\n",
    "    print(f\"  Attack Success Rate: {results['avg_attack_success_rate']:.4f} ± {results['std_attack_success_rate']:.4f}\")\n",
    "    print(f\"  Number of images saved: {results['num_images']}\")\n",
    "    print(f\"  Save directory: {results['save_directory']}\")\n",
    "    \n",
    "    # 8. Save results to CSV\n",
    "    df = pd.DataFrame([results])\n",
    "    results_csv = os.path.join(ADV_SAVE_DIR, \"deeplabv3_pgd_results_5000imgs.csv\")\n",
    "    df.to_csv(results_csv, index=False)\n",
    "    print(f\"\\n[INFO] Results saved to: {results_csv}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"DEEPLABV3 PGD ATTACK RESULTS (5000 TEST IMAGES)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Pixel Accuracy: {results['avg_pixel_accuracy']:.4f}\")\n",
    "    print(f\"mIoU: {results['avg_miou']:.4f}\")\n",
    "    print(f\"Attack Success Rate: {results['avg_attack_success_rate']:.4f}\")\n",
    "    print(f\"Images processed: {results['num_images']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
